{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arabic_sentiment_analysis_capstone_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjx2Vty-oVuD"
      },
      "source": [
        "# Arabic Tweets Sentiment Anaylsis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0sZNw82okiv"
      },
      "source": [
        "## Introduction\r\n",
        "\r\n",
        "This dataset we collected in April 2019 by an company. It contains 58K Arabic tweets annotated in positive and negative labels, The company collected this dataset to provide Arabic sentiment corpus for the research the comapny doing to investigate deep learning approaches for Arabic sentiment analysis. The dataset is balanced and collected using positive and negative emojis lexicon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GwMQzORpCdV"
      },
      "source": [
        "## Exploring and downloading the Text data files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAszVBTUjN1z"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdzUap76p-3t"
      },
      "source": [
        "tweets_data_negative = pd.read_csv('/content/train_Arabic_tweets_negative_20190413.tsv',sep='\\t',header=None, encoding='utf-8')\r\n",
        "tweets_data_positive = pd.read_csv('/content/train_Arabic_tweets_positive_20190413.tsv',sep='\\t',header=None, encoding='utf-8')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "K7pWMqHSqZyi",
        "outputId": "d6db197b-4352-44b7-c2c2-66e96df6b84d"
      },
      "source": [
        "tweets_data_negative.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>اعترف ان بتس كانو شوي شوي يجيبو راسي لكن اليوم...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>توقعت اذا جات داريا بشوفهم كاملين بس لي للحين ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>#الاهلي_الهلال اكتب توقعك لنتيجة لقاء الهلال و...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>نعمة المضادات الحيوية . تضع قطرة💧مضاد بنسلين ع...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>الدودو جايه تكمل علي 💔</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0                                                  1\n",
              "0  neg  اعترف ان بتس كانو شوي شوي يجيبو راسي لكن اليوم...\n",
              "1  neg  توقعت اذا جات داريا بشوفهم كاملين بس لي للحين ...\n",
              "2  neg  #الاهلي_الهلال اكتب توقعك لنتيجة لقاء الهلال و...\n",
              "3  neg  نعمة المضادات الحيوية . تضع قطرة💧مضاد بنسلين ع...\n",
              "4  neg                             الدودو جايه تكمل علي 💔"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LYDBBVzgqmD5",
        "outputId": "80ff33eb-dd65-4ffd-9eeb-887aac2fa8b4"
      },
      "source": [
        "tweets_data_positive.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>نحن الذين يتحول كل ما نود أن نقوله إلى دعاء لل...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pos</td>\n",
              "      <td>وفي النهاية لن يبقىٰ معك آحدإلا من رأىٰ الجمال...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>من الخير نفسه 💛</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>#زلزل_الملعب_نصرنا_بيلعب كن عالي الهمه ولا ترض...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>الشيء الوحيد الذي وصلوا فيه للعالمية هو : المس...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0                                                  1\n",
              "0  pos  نحن الذين يتحول كل ما نود أن نقوله إلى دعاء لل...\n",
              "1  pos  وفي النهاية لن يبقىٰ معك آحدإلا من رأىٰ الجمال...\n",
              "2  pos                                    من الخير نفسه 💛\n",
              "3  pos  #زلزل_الملعب_نصرنا_بيلعب كن عالي الهمه ولا ترض...\n",
              "4  pos  الشيء الوحيد الذي وصلوا فيه للعالمية هو : المس..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neXthPenReU3"
      },
      "source": [
        "we see that there is two labels \"neg\" and \"pos\" in the class seprated in two dataframes so i said i work on them together in one dataframe so i will concate them for better exploration on the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOH1j1vGqwNT"
      },
      "source": [
        "fulldf = pd.concat([tweets_data_negative,tweets_data_positive], ignore_index=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "aewuAoeF-6u5",
        "outputId": "669e2260-653e-40f6-d592-d9c45b952ca4"
      },
      "source": [
        "fulldf.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>اعترف ان بتس كانو شوي شوي يجيبو راسي لكن اليوم...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>توقعت اذا جات داريا بشوفهم كاملين بس لي للحين ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>#الاهلي_الهلال اكتب توقعك لنتيجة لقاء الهلال و...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>نعمة المضادات الحيوية . تضع قطرة💧مضاد بنسلين ع...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>الدودو جايه تكمل علي 💔</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0                                                  1\n",
              "0  neg  اعترف ان بتس كانو شوي شوي يجيبو راسي لكن اليوم...\n",
              "1  neg  توقعت اذا جات داريا بشوفهم كاملين بس لي للحين ...\n",
              "2  neg  #الاهلي_الهلال اكتب توقعك لنتيجة لقاء الهلال و...\n",
              "3  neg  نعمة المضادات الحيوية . تضع قطرة💧مضاد بنسلين ع...\n",
              "4  neg                             الدودو جايه تكمل علي 💔"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "wrgUMSpe_v42",
        "outputId": "4382dae9-ab67-49dd-e6a0-5ba74bdd63b8"
      },
      "source": [
        "fulldf.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>45275</td>\n",
              "      <td>45275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>29449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>pos</td>\n",
              "      <td>بمناسبة فوز الهلال .. 💙 سحب على آيفون XR📱 رتوي...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>22761</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0                                                  1\n",
              "count   45275                                              45275\n",
              "unique      2                                              29449\n",
              "top       pos  بمناسبة فوز الهلال .. 💙 سحب على آيفون XR📱 رتوي...\n",
              "freq    22761                                                349"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85TSkkyQ_0S4",
        "outputId": "b23068b6-5ce4-44f4-f5e2-971d032fc5c1"
      },
      "source": [
        "fulldf.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45275 entries, 0 to 45274\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       45275 non-null  object\n",
            " 1   1       45275 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 707.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQfQnDxg_8b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ceca14-7779-4ff8-e25c-2bd7e2a804fc"
      },
      "source": [
        "fulldf.columns"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([0, 1], dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MYIhQkZR_jI"
      },
      "source": [
        "fulldf.columns = ['class','Tweets']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SspYGr6ZSdv1",
        "outputId": "cc645a2f-da2e-460f-baac-11585de9b325"
      },
      "source": [
        "fulldf.columns\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['class', 'Tweets'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OO3mrnScUHD0",
        "outputId": "126f3efc-91ad-444e-a7e4-6b1e609eea41"
      },
      "source": [
        "fulldf.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>اعترف ان بتس كانو شوي شوي يجيبو راسي لكن اليوم...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>توقعت اذا جات داريا بشوفهم كاملين بس لي للحين ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>#الاهلي_الهلال اكتب توقعك لنتيجة لقاء الهلال و...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>نعمة المضادات الحيوية . تضع قطرة💧مضاد بنسلين ع...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>الدودو جايه تكمل علي 💔</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  class                                             Tweets\n",
              "0   neg  اعترف ان بتس كانو شوي شوي يجيبو راسي لكن اليوم...\n",
              "1   neg  توقعت اذا جات داريا بشوفهم كاملين بس لي للحين ...\n",
              "2   neg  #الاهلي_الهلال اكتب توقعك لنتيجة لقاء الهلال و...\n",
              "3   neg  نعمة المضادات الحيوية . تضع قطرة💧مضاد بنسلين ع...\n",
              "4   neg                             الدودو جايه تكمل علي 💔"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtQ67AObUKbn"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdiMhJLgUXGp"
      },
      "source": [
        "we need to make sure that we have both neg and pos rows too "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLTPH3sNUdnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7d0e53-1447-45ab-9cdf-e4e49434f03e"
      },
      "source": [
        "fulldf['class'].unique()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['neg', 'pos'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqHkoUCE7tU0"
      },
      "source": [
        "Checking for nulls:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXPv04h37nxW",
        "outputId": "faa83a3f-4597-4090-f8d9-0d578fde8d3c"
      },
      "source": [
        "fulldf.isna().sum()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class     0\n",
              "Tweets    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSNlr-R6U5Px"
      },
      "source": [
        "# Data Exploration and cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8M2DuD05QL8"
      },
      "source": [
        "first lets import the libraries we will need in this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eGl36fO5bGy"
      },
      "source": [
        "First lets install our graphics tools from python like:\r\n",
        " \r\n",
        "*    plotly: plotly.py is an interactive, open-source, and browser-based graphing library for Python https://github.com/plotly/plotly.py\r\n",
        "\r\n",
        "*   cufflinks: This library binds the power of plotly with the flexibility of pandas for easy plotting. https://github.com/santosjorge/cufflinks\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWujFvWG5WUF",
        "outputId": "505535ee-fd4f-4da3-c5b1-4d0cd3055d99"
      },
      "source": [
        "!pip install plotly"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (4.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly) (1.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfjPgeJi6XFD",
        "outputId": "cded9937-8d3c-4396-dc9e-a84b809e539b"
      },
      "source": [
        "!pip install cufflinks"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cufflinks in /usr/local/lib/python3.6/dist-packages (0.17.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from cufflinks) (1.15.0)\n",
            "Requirement already satisfied: plotly>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks) (4.4.1)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks) (51.1.2)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.6/dist-packages (from cufflinks) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from cufflinks) (1.19.5)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from cufflinks) (7.6.3)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.6/dist-packages (from cufflinks) (1.1.5)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks) (0.3.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.1->cufflinks) (1.3.3)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.3.0->cufflinks) (0.8.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->cufflinks) (5.0.8)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->cufflinks) (3.5.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->cufflinks) (4.10.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->cufflinks) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->cufflinks) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.2->cufflinks) (2.8.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.3.0->cufflinks) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.3.0->cufflinks) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.3.0->cufflinks) (0.2.5)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->cufflinks) (4.7.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (5.3.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (5.1.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (2.11.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.9.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.5.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->cufflinks) (20.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.1.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (3.2.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (1.4.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (20.8)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (0.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->cufflinks) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL1ngKVl6aQB"
      },
      "source": [
        "now the rest of the important libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSgTmAEy6mcF",
        "outputId": "f9235cbb-0526-47c0-e56a-b7fbf46ecbe9"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from collections import Counter\r\n",
        "import nltk\r\n",
        "import pandas as pd\r\n",
        "import re as regex\r\n",
        "import numpy as np\r\n",
        "import plotly\r\n",
        "from plotly import graph_objs\r\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\r\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\r\n",
        "from time import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "import seaborn as sns\r\n",
        "import plotly\r\n",
        "import cufflinks as cf\r\n",
        "import re\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHP8IK0yU-ue"
      },
      "source": [
        "now we need to clean the tweets texts and do some tokenization and stemming and maybe adding more feauters to the dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG3dkTqG63mL"
      },
      "source": [
        "Lets do some visualization for the distrbution of the target class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "7Ch20Gr8UuYs",
        "outputId": "618a45d7-cc06-4fdc-b2c1-7b670079478f"
      },
      "source": [
        "sns.countplot(x='class',data=fulldf)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f781f6ccc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-T8m4py7eKH"
      },
      "source": [
        "Now lets start with cleaning the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S1fbp4R7TU1"
      },
      "source": [
        "def clean_tweets(tweet):\r\n",
        "    \r\n",
        "    # remove URL\r\n",
        "    tweet = re.sub('http\\S+\\s*', ' ', tweet)\r\n",
        "    \r\n",
        "    # Remove usernames\r\n",
        "    tweet = re.sub(r\"@[^\\s]+[\\s]?\",'',tweet)\r\n",
        "    \r\n",
        "    # remove special characters \r\n",
        "    tweet = re.sub(\"@[ا-ي0-9]+\", \" \", tweet)\r\n",
        "    tweet = re.sub(\"[أ-ي]#+\", \" \", tweet)\r\n",
        "    tweet = re.sub(\"#[أ-ي]+\", \" \", tweet)\r\n",
        "    \r\n",
        "    # remove Numbers\r\n",
        "    tweet = re.sub('^[\\u0621-\\u064A\\u0660-\\u0669 ]+$', '', tweet)\r\n",
        "    tweet = re.sub('\\.+', '', tweet)\r\n",
        "    tweet = re.sub(':', '', tweet)\r\n",
        "    tweet = re.sub('!', '', tweet)\r\n",
        "    tweet = re.sub('،','',tweet)\r\n",
        "    tweet = re.sub('-','',tweet)\r\n",
        "    tweet = re.sub('_','',tweet)\r\n",
        "    return tweet"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYWtWS4--vjY"
      },
      "source": [
        "Now lets apply this function to clean the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAvlepw19yMI"
      },
      "source": [
        "fulldf['Tweets'] = fulldf['Tweets'].apply(clean_tweets)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2-hGfRY-0Nz"
      },
      "source": [
        "Now lets see how the first 5 rows looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj6bXDHU-n2p",
        "outputId": "f521666d-75c4-40fa-8288-14cde323220d"
      },
      "source": [
        "fulldf['Tweets'].head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    اعترف ان بتس كانو شوي شوي يجيبو راسي لكن اليوم...\n",
              "1    توقعت اذا جات داريا بشوفهم كاملين بس لي للحين ...\n",
              "2     الهلال اكتب توقعك لنتيجة لقاء الهلال والاهلي ...\n",
              "3    نعمة المضادات الحيوية  تضع قطرة💧مضاد بنسلين عل...\n",
              "4                               الدودو جايه تكمل علي 💔\n",
              "Name: Tweets, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB6mLFbn_dia"
      },
      "source": [
        "# Tokenization And Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c7OMgQU_9xM"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNmC_liV-79K",
        "outputId": "2f590a0a-37c6-4b16-80c9-506ad0a7a01e"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\r\n",
        "from nltk.tokenize import  word_tokenize\r\n",
        "tt = TweetTokenizer()\r\n",
        "fulldf['Tweets'].apply(tt.tokenize)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [اعترف, ان, بتس, كانو, شوي, شوي, يجيبو, راسي, ...\n",
              "1        [توقعت, اذا, جات, داريا, بشوفهم, كاملين, بس, ل...\n",
              "2        [الهلال, اكتب, توقعك, لنتيجة, لقاء, الهلال, وا...\n",
              "3        [نعمة, المضادات, الحيوية, تضع, قطرة, 💧, مضاد, ...\n",
              "4                             [الدودو, جايه, تكمل, علي, 💔]\n",
              "                               ...                        \n",
              "45270    [السحب, الليلة, على, الايفون, رتويت, للمرفقة, ...\n",
              "45271    [😂, لابسة, احمر, ليه, يا, ست, انتي, ايه, المنا...\n",
              "45272    [كلاام, جمييل, تستاهل, (, من, احبه, الله, جعل,...\n",
              "45273               [ألطف, صورة, ممكن, تعبر, عن, رمضان, 💙]\n",
              "45274    [🌸, قال, ابنالقيم, رحمه, الله, تعالى, \", فإن, ...\n",
              "Name: Tweets, Length: 45275, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh4cPufHABCM"
      },
      "source": [
        "## Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHhZH9H-_2YP"
      },
      "source": [
        "from nltk.stem import PorterStemmer\r\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\r\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR8HN--hBUcU"
      },
      "source": [
        "So what is stemming for?\r\n",
        "  Its a normilization method for basically to normalize words and shorten the lookup because many vartions of words carry the same meaning other then when tense is involed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcT2Ozy9BP8C"
      },
      "source": [
        "def tokenize(text):\r\n",
        "  return word_tokenize(text)\r\n",
        "\r\n",
        "def stemming(words):\r\n",
        "  stem_words = []\r\n",
        "  for w in words:\r\n",
        "    w = ps.stem(w)\r\n",
        "    stem_words.append(w)\r\n",
        "    return stem_words"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP-BNVuWD2AG"
      },
      "source": [
        "Now lets apply the tokenize function on the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OK9esb4D1O7"
      },
      "source": [
        "fulldf['text'] = fulldf['Tweets'].apply(tokenize)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfwJepk3ER3B"
      },
      "source": [
        "And now stemming function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tf4ytA0EJcW"
      },
      "source": [
        "fulldf['Tokenized'] = fulldf['Tweets'].apply(stemming)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Br3L6OpwEUvy",
        "outputId": "c64142d1-8801-44a6-e088-c8bd00256411"
      },
      "source": [
        "fulldf.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>text</th>\n",
              "      <th>Tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neg</td>\n",
              "      <td>اعترف ان بتس كانو شوي شوي يجيبو راسي لكن اليوم...</td>\n",
              "      <td>[اعترف, ان, بتس, كانو, شوي, شوي, يجيبو, راسي, ...</td>\n",
              "      <td>[ا]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>توقعت اذا جات داريا بشوفهم كاملين بس لي للحين ...</td>\n",
              "      <td>[توقعت, اذا, جات, داريا, بشوفهم, كاملين, بس, ل...</td>\n",
              "      <td>[ت]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neg</td>\n",
              "      <td>الهلال اكتب توقعك لنتيجة لقاء الهلال والاهلي ...</td>\n",
              "      <td>[الهلال, اكتب, توقعك, لنتيجة, لقاء, الهلال, وا...</td>\n",
              "      <td>[ ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>نعمة المضادات الحيوية  تضع قطرة💧مضاد بنسلين عل...</td>\n",
              "      <td>[نعمة, المضادات, الحيوية, تضع, قطرة💧مضاد, بنسل...</td>\n",
              "      <td>[ن]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>الدودو جايه تكمل علي 💔</td>\n",
              "      <td>[الدودو, جايه, تكمل, علي, 💔]</td>\n",
              "      <td>[ا]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  class  ... Tokenized\n",
              "0   neg  ...       [ا]\n",
              "1   neg  ...       [ت]\n",
              "2   neg  ...       [ ]\n",
              "3   neg  ...       [ن]\n",
              "4   neg  ...       [ا]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGgfU8R8EboQ"
      },
      "source": [
        "We can see that we have now two new featuers text that has been tokenized in the text featuer and the stemming in the tokeinzed featuer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4G0lYtm8EqDx"
      },
      "source": [
        "Now lets see the lenght of rows in this dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gAs2mg7EXtB",
        "outputId": "e936cf0c-29a3-42f5-e0ea-a9a737d8b907"
      },
      "source": [
        "len(fulldf)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45275"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKP-9rRDFrvD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvg_EU-lFr6E"
      },
      "source": [
        "# Wordlist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-mYjOypEwCi"
      },
      "source": [
        "words = Counter()\r\n",
        "for idx in fulldf.index:\r\n",
        "  words.update(fulldf.loc[idx,\"text\"])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opybFmBGGDJs",
        "outputId": "9ff5518e-4734-4d0a-fb4e-fa6732d392bd"
      },
      "source": [
        "words.most_common(10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('من', 10173),\n",
              " ('في', 7451),\n",
              " ('الله', 6572),\n",
              " ('و', 5297),\n",
              " ('💔', 4989),\n",
              " ('على', 4957),\n",
              " ('لا', 3918),\n",
              " ('ما', 3617),\n",
              " ('😂', 2801),\n",
              " ('كل', 2758)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL-YRY0tGNjI"
      },
      "source": [
        "Stop words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8FZANqWGFpm",
        "outputId": "c4e42cf1-2490-44fe-e093-b7b769d572cc"
      },
      "source": [
        "nltk.download('stopwords')\r\n",
        "stopwords=nltk.corpus.stopwords.words(\"arabic\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCXrO8A5GgcT",
        "outputId": "a060695a-3bb6-4b44-e36a-40ce4ce35b22"
      },
      "source": [
        "stopwords"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['إذ',\n",
              " 'إذا',\n",
              " 'إذما',\n",
              " 'إذن',\n",
              " 'أف',\n",
              " 'أقل',\n",
              " 'أكثر',\n",
              " 'ألا',\n",
              " 'إلا',\n",
              " 'التي',\n",
              " 'الذي',\n",
              " 'الذين',\n",
              " 'اللاتي',\n",
              " 'اللائي',\n",
              " 'اللتان',\n",
              " 'اللتيا',\n",
              " 'اللتين',\n",
              " 'اللذان',\n",
              " 'اللذين',\n",
              " 'اللواتي',\n",
              " 'إلى',\n",
              " 'إليك',\n",
              " 'إليكم',\n",
              " 'إليكما',\n",
              " 'إليكن',\n",
              " 'أم',\n",
              " 'أما',\n",
              " 'أما',\n",
              " 'إما',\n",
              " 'أن',\n",
              " 'إن',\n",
              " 'إنا',\n",
              " 'أنا',\n",
              " 'أنت',\n",
              " 'أنتم',\n",
              " 'أنتما',\n",
              " 'أنتن',\n",
              " 'إنما',\n",
              " 'إنه',\n",
              " 'أنى',\n",
              " 'أنى',\n",
              " 'آه',\n",
              " 'آها',\n",
              " 'أو',\n",
              " 'أولاء',\n",
              " 'أولئك',\n",
              " 'أوه',\n",
              " 'آي',\n",
              " 'أي',\n",
              " 'أيها',\n",
              " 'إي',\n",
              " 'أين',\n",
              " 'أين',\n",
              " 'أينما',\n",
              " 'إيه',\n",
              " 'بخ',\n",
              " 'بس',\n",
              " 'بعد',\n",
              " 'بعض',\n",
              " 'بك',\n",
              " 'بكم',\n",
              " 'بكم',\n",
              " 'بكما',\n",
              " 'بكن',\n",
              " 'بل',\n",
              " 'بلى',\n",
              " 'بما',\n",
              " 'بماذا',\n",
              " 'بمن',\n",
              " 'بنا',\n",
              " 'به',\n",
              " 'بها',\n",
              " 'بهم',\n",
              " 'بهما',\n",
              " 'بهن',\n",
              " 'بي',\n",
              " 'بين',\n",
              " 'بيد',\n",
              " 'تلك',\n",
              " 'تلكم',\n",
              " 'تلكما',\n",
              " 'ته',\n",
              " 'تي',\n",
              " 'تين',\n",
              " 'تينك',\n",
              " 'ثم',\n",
              " 'ثمة',\n",
              " 'حاشا',\n",
              " 'حبذا',\n",
              " 'حتى',\n",
              " 'حيث',\n",
              " 'حيثما',\n",
              " 'حين',\n",
              " 'خلا',\n",
              " 'دون',\n",
              " 'ذا',\n",
              " 'ذات',\n",
              " 'ذاك',\n",
              " 'ذان',\n",
              " 'ذانك',\n",
              " 'ذلك',\n",
              " 'ذلكم',\n",
              " 'ذلكما',\n",
              " 'ذلكن',\n",
              " 'ذه',\n",
              " 'ذو',\n",
              " 'ذوا',\n",
              " 'ذواتا',\n",
              " 'ذواتي',\n",
              " 'ذي',\n",
              " 'ذين',\n",
              " 'ذينك',\n",
              " 'ريث',\n",
              " 'سوف',\n",
              " 'سوى',\n",
              " 'شتان',\n",
              " 'عدا',\n",
              " 'عسى',\n",
              " 'عل',\n",
              " 'على',\n",
              " 'عليك',\n",
              " 'عليه',\n",
              " 'عما',\n",
              " 'عن',\n",
              " 'عند',\n",
              " 'غير',\n",
              " 'فإذا',\n",
              " 'فإن',\n",
              " 'فلا',\n",
              " 'فمن',\n",
              " 'في',\n",
              " 'فيم',\n",
              " 'فيما',\n",
              " 'فيه',\n",
              " 'فيها',\n",
              " 'قد',\n",
              " 'كأن',\n",
              " 'كأنما',\n",
              " 'كأي',\n",
              " 'كأين',\n",
              " 'كذا',\n",
              " 'كذلك',\n",
              " 'كل',\n",
              " 'كلا',\n",
              " 'كلاهما',\n",
              " 'كلتا',\n",
              " 'كلما',\n",
              " 'كليكما',\n",
              " 'كليهما',\n",
              " 'كم',\n",
              " 'كم',\n",
              " 'كما',\n",
              " 'كي',\n",
              " 'كيت',\n",
              " 'كيف',\n",
              " 'كيفما',\n",
              " 'لا',\n",
              " 'لاسيما',\n",
              " 'لدى',\n",
              " 'لست',\n",
              " 'لستم',\n",
              " 'لستما',\n",
              " 'لستن',\n",
              " 'لسن',\n",
              " 'لسنا',\n",
              " 'لعل',\n",
              " 'لك',\n",
              " 'لكم',\n",
              " 'لكما',\n",
              " 'لكن',\n",
              " 'لكنما',\n",
              " 'لكي',\n",
              " 'لكيلا',\n",
              " 'لم',\n",
              " 'لما',\n",
              " 'لن',\n",
              " 'لنا',\n",
              " 'له',\n",
              " 'لها',\n",
              " 'لهم',\n",
              " 'لهما',\n",
              " 'لهن',\n",
              " 'لو',\n",
              " 'لولا',\n",
              " 'لوما',\n",
              " 'لي',\n",
              " 'لئن',\n",
              " 'ليت',\n",
              " 'ليس',\n",
              " 'ليسا',\n",
              " 'ليست',\n",
              " 'ليستا',\n",
              " 'ليسوا',\n",
              " 'ما',\n",
              " 'ماذا',\n",
              " 'متى',\n",
              " 'مذ',\n",
              " 'مع',\n",
              " 'مما',\n",
              " 'ممن',\n",
              " 'من',\n",
              " 'منه',\n",
              " 'منها',\n",
              " 'منذ',\n",
              " 'مه',\n",
              " 'مهما',\n",
              " 'نحن',\n",
              " 'نحو',\n",
              " 'نعم',\n",
              " 'ها',\n",
              " 'هاتان',\n",
              " 'هاته',\n",
              " 'هاتي',\n",
              " 'هاتين',\n",
              " 'هاك',\n",
              " 'هاهنا',\n",
              " 'هذا',\n",
              " 'هذان',\n",
              " 'هذه',\n",
              " 'هذي',\n",
              " 'هذين',\n",
              " 'هكذا',\n",
              " 'هل',\n",
              " 'هلا',\n",
              " 'هم',\n",
              " 'هما',\n",
              " 'هن',\n",
              " 'هنا',\n",
              " 'هناك',\n",
              " 'هنالك',\n",
              " 'هو',\n",
              " 'هؤلاء',\n",
              " 'هي',\n",
              " 'هيا',\n",
              " 'هيت',\n",
              " 'هيهات',\n",
              " 'والذي',\n",
              " 'والذين',\n",
              " 'وإذ',\n",
              " 'وإذا',\n",
              " 'وإن',\n",
              " 'ولا',\n",
              " 'ولكن',\n",
              " 'ولو',\n",
              " 'وما',\n",
              " 'ومن',\n",
              " 'وهو',\n",
              " 'يا']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fRnpLooGpVH"
      },
      "source": [
        "lets have our whitelist:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLykPBDLGjuX",
        "outputId": "d06a4c79-0bbd-412d-d614-d99540f172ad"
      },
      "source": [
        "whitelist= ['لأن','لئن']\r\n",
        "whitelist"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['لأن', 'لئن']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dernOpWPI1yb",
        "outputId": "acd619b8-72d8-4f79-9a85-545d0d81363d"
      },
      "source": [
        "for idx,stop_word in enumerate(stopwords):\r\n",
        "  if stop_word not in whitelist:\r\n",
        "    del words[stop_word]\r\n",
        "words.most_common(10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('الله', 6572),\n",
              " ('و', 5297),\n",
              " ('💔', 4989),\n",
              " ('😂', 2801),\n",
              " ('💙', 2531),\n",
              " ('اللهم', 2316),\n",
              " ('صباح', 1965),\n",
              " ('(', 1908),\n",
              " ('😭', 1893),\n",
              " ('والله', 1612)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHFAWLsYJdrJ"
      },
      "source": [
        "def word_list(processed_data):\r\n",
        "    #print(processed_data)\r\n",
        "    min_occurrences=3 \r\n",
        "    max_occurences=500 \r\n",
        "    stopwords=nltk.corpus.stopwords.words(\"arabic\")\r\n",
        "    whitelist = ['لأن','لئن']\r\n",
        "    wordlist = []\r\n",
        "    \r\n",
        "    whitelist = whitelist if whitelist is None else whitelist\r\n",
        "   # print(whitelist)\r\n",
        "    words = Counter()\r\n",
        "    for idx in processed_data.index:\r\n",
        "        words.update(processed_data.loc[idx, \"text\"])\r\n",
        "\r\n",
        "    for idx, stop_word in enumerate(stopwords):\r\n",
        "        if stop_word not in whitelist:\r\n",
        "            del words[stop_word]\r\n",
        "    #print(words)\r\n",
        "\r\n",
        "    word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\r\n",
        "                                 \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\r\n",
        "                           columns=[\"word\", \"occurrences\"])\r\n",
        "    #print(word_df)\r\n",
        "    word_df.to_csv(\"wordlist.csv\", index_label=\"idx\")\r\n",
        "    wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\r\n",
        "    #print(wordlist)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8qGOCZcQzRd"
      },
      "source": [
        "word_list(fulldf)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EKI3EYLXQ35s",
        "outputId": "2d728370-3885-423c-95cc-70b7e7a4c04e"
      },
      "source": [
        "words = pd.read_csv(\"wordlist.csv\")\r\n",
        "words.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>word</th>\n",
              "      <th>occurrences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>اذا</td>\n",
              "      <td>498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ي</td>\n",
              "      <td>497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>💪</td>\n",
              "      <td>480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>او</td>\n",
              "      <td>469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>محمد</td>\n",
              "      <td>469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   idx  word  occurrences\n",
              "0    0   اذا          498\n",
              "1    1     ي          497\n",
              "2    2     💪          480\n",
              "3    3    او          469\n",
              "4    4  محمد          469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}